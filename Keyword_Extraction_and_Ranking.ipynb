{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keyword-Extraction-and-Ranking.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNrcbXp0gkX+MJZ6Q4HjyNl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhadreshpsavani/NLP-based-Article-Analysis/blob/main/Keyword_Extraction_and_Ranking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSqHd7ze64TY"
      },
      "source": [
        "# Keyword Extraction and Ranking:\r\n",
        "We have a Query and an Article. **We want to find keywords/Tags from Article Which is best suitable for given query.**\r\n",
        "\r\n",
        "## Approach:\r\n",
        "I see this problem as two task:\r\n",
        "1. Keyword Extraction\r\n",
        "2. Similarity check\r\n",
        "\r\n",
        "## 1. Keyword Extraction:\r\n",
        "**We have to find Keywords from given Article**\r\n",
        "\r\n",
        "There are Unsupervised Machine Learning state of the art approches like TF.IDF, KP-Miner, RAKE, TextRank, SingleRank, ExpandRank, TopicRank, TopicalPageRank, PositionRank, MultipartiteRank etc which relies on statistics of Text and one supervised method (KEA). \r\n",
        "\r\n",
        "Experimental results carried out on top of twenty datasets (see Benchmark section below) show that [YAKE](https://github.com/LIAAD/yake) methods significantly outperform state-of-the-art methods under a number of collections of different sizes, languages or domains.\r\n",
        "\r\n",
        "### Features:\r\n",
        "* Unsupervised approach\r\n",
        "* Corpus-Independent\r\n",
        "* Domain and Language Independent\r\n",
        "* Single-Document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LV8wU-P6tsH",
        "outputId": "3ab4cea3-95e9-4d28-d45a-b31834f202d8"
      },
      "source": [
        "# install packages\r\n",
        "!pip install -q  git+https://github.com/LIAAD/yake\r\n",
        "!pip install -q transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▌                            | 10kB 30.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 20kB 36.3MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 30kB 40.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 40kB 41.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 51kB 42.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 61kB 44.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 71kB 43.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 81kB 39.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 92kB 39.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 13.6MB/s \n",
            "\u001b[?25h  Building wheel for yake (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 15.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 50.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 53.7MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ehox7M0I98j4"
      },
      "source": [
        "import yake\r\n",
        "from transformers import pipeline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAkoX0i9-ISl"
      },
      "source": [
        "## Example\r\n",
        "text = \"Sources tell us that Google is acquiring Kaggle, a platform that hosts data science and machine learning \"\\\r\n",
        "\"competitions. Details about the transaction remain somewhat vague, but given that Google is hosting its Cloud \"\\\r\n",
        "\"Next conference in San Francisco this week, the official announcement could come as early as tomorrow. \"\\\r\n",
        "\"Reached by phone, Kaggle co-founder CEO Anthony Goldbloom declined to deny that the acquisition is happening. \"\\\r\n",
        "\"Google itself declined 'to comment on rumors'. Kaggle, which has about half a million data scientists on its platform, \"\\\r\n",
        "\"was founded by Goldbloom  and Ben Hamner in 2010. \"\\\r\n",
        "\"The service got an early start and even though it has a few competitors like DrivenData, TopCoder and HackerRank, \"\\\r\n",
        "\"it has managed to stay well ahead of them by focusing on its specific niche. \"\\\r\n",
        "\"The service is basically the de facto home for running data science and machine learning competitions. \"\\\r\n",
        "\"With Kaggle, Google is buying one of the largest and most active communities for data scientists - and with that, \"\\\r\n",
        "\"it will get increased mindshare in this community, too (though it already has plenty of that thanks to Tensorflow \"\\\r\n",
        "\"and other projects). Kaggle has a bit of a history with Google, too, but that's pretty recent. Earlier this month, \"\\\r\n",
        "\"Google and Kaggle teamed up to host a $100,000 machine learning competition around classifying YouTube videos. \"\\\r\n",
        "\"That competition had some deep integrations with the Google Cloud Platform, too. Our understanding is that Google \"\\\r\n",
        "\"will keep the service running - likely under its current name. While the acquisition is probably more about \"\\\r\n",
        "\"Kaggle's community than technology, Kaggle did build some interesting tools for hosting its competition \"\\\r\n",
        "\"and 'kernels', too. On Kaggle, kernels are basically the source code for analyzing data sets and developers can \"\\\r\n",
        "\"share this code on the platform (the company previously called them 'scripts'). \"\\\r\n",
        "\"Like similar competition-centric sites, Kaggle also runs a job board, too. It's unclear what Google will do with \"\\\r\n",
        "\"that part of the service. According to Crunchbase, Kaggle raised $12.5 million (though PitchBook says it's $12.75) \"\\\r\n",
        "\"since its   launch in 2010. Investors in Kaggle include Index Ventures, SV Angel, Max Levchin, Naval Ravikant, \"\\\r\n",
        "\"Google chief economist Hal Varian, Khosla Ventures and Yuri Milner \""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-goBBYD-LUL"
      },
      "source": [
        "def keyword_extractor(language=\"en\", max_ngram_size=3, deduplication_thresold=0.9, deduplication_algo='seqm', windowSize=1, numOfKeywords=20, features=None, stopwords=None):\r\n",
        "  \"\"\"\r\n",
        "  This function will take following parameters as input\r\n",
        "    language, \r\n",
        "    max_ngram_size, \r\n",
        "    deduplication_thresold, \r\n",
        "    deduplication_algo, \r\n",
        "    windowSize, \r\n",
        "    numOfKeywords, \r\n",
        "    features, \r\n",
        "    stopwords\r\n",
        "  according to KeywordExtractor() from https://github.com/LIAAD/yake/blob/master/yake/yake.py\r\n",
        "  and \r\n",
        "  return list of tuple of keyword with its candidate value/confidence score \r\n",
        "  \"\"\"\r\n",
        "  custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, \r\n",
        "                                              dedupLim=deduplication_thresold, \r\n",
        "                                              dedupFunc=deduplication_algo, \r\n",
        "                                              windowsSize=windowSize, \r\n",
        "                                              top=numOfKeywords, \r\n",
        "                                              features=features,\r\n",
        "                                              stopwords=stopwords)\r\n",
        "\r\n",
        "  keywords = custom_kw_extractor.extract_keywords(text)\r\n",
        "  keywords.sort(key=lambda items: -items[1]) # sort it in decreasing order of candidate value\r\n",
        "  return keywords"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IbXhZVo-X2r",
        "outputId": "6346a7a5-a24a-48e1-9da1-f8e06f015712"
      },
      "source": [
        "%%time\r\n",
        "language = \"en\"\r\n",
        "max_ngram_size = 3\r\n",
        "deduplication_thresold = 0.9\r\n",
        "deduplication_algo = 'seqm'\r\n",
        "windowSize = 1\r\n",
        "numOfKeywords = 20\r\n",
        "\r\n",
        "keywords = keyword_extractor(language, \r\n",
        "                            max_ngram_size, \r\n",
        "                            deduplication_thresold, \r\n",
        "                            deduplication_algo, \r\n",
        "                            windowSize, \r\n",
        "                            numOfKeywords)\r\n",
        "\r\n",
        "for kw in keywords:\r\n",
        "    print(kw)\r\n",
        "\r\n",
        "keywords_list = [keyword[0] for keyword in keywords]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('goldbloom', 0.14611408778815776)\n",
            "('service', 0.12546743261462942)\n",
            "('conference in san', 0.12392066376108138)\n",
            "('platform', 0.1183512305596321)\n",
            "('francisco this week', 0.11519915079240485)\n",
            "('machine learning competitions', 0.10773000650607861)\n",
            "('google cloud', 0.10260128641464673)\n",
            "('data', 0.097574333771058)\n",
            "('kaggle co-founder ceo', 0.093805063905847)\n",
            "('machine learning', 0.09147989238151344)\n",
            "('anthony goldbloom', 0.09123482372372106)\n",
            "('ceo anthony', 0.08915156857226395)\n",
            "('acquiring kaggle', 0.08723571551039863)\n",
            "('co-founder ceo anthony', 0.07357749587020043)\n",
            "('google cloud platform', 0.06261974476422487)\n",
            "('anthony goldbloom declined', 0.06176910090701819)\n",
            "('san francisco', 0.048810837074825336)\n",
            "('ceo anthony goldbloom', 0.029946071606210194)\n",
            "('kaggle', 0.0289005976239829)\n",
            "('google', 0.026580863364597897)\n",
            "CPU times: user 108 ms, sys: 1.85 ms, total: 110 ms\n",
            "Wall time: 111 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0-oTEQ-Bvs-"
      },
      "source": [
        "## 2. Getting Suitable Keywords\r\n",
        "\r\n",
        "**We have list of keywords and a query, we need to find top matching keywords with given query**\r\n",
        "\r\n",
        "We will use Huggingface Zeroshot learning pipeline which uses model trained on NLI task (Natural Language Infernece). It is classification task having three labels:\r\n",
        "1. Contradiction\r\n",
        "2. Neutral\r\n",
        "3. Entailment\r\n",
        "\r\n",
        "Basically the model is trained to compare two sentence. We can use this model to check the simiality of keywords/labels/tags with query according to Zero-Shot-Classification problem\r\n",
        "\r\n",
        "### Advantage of ZeroShotLearning Pipeline:\r\n",
        "1. Domain Independent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AO7ULLVwBSaH",
        "outputId": "d577211f-f55f-4d81-d3c9-2bfc771c16c5"
      },
      "source": [
        "# the pipeline uses bart-large-mnli by default, we use our own custom \r\n",
        "# trained model on NLI task\r\n",
        "# classifier = pipeline(\"zero-shot-classification\") # cpu\r\n",
        "classifier = pipeline(\"zero-shot-classification\", device=0) # to utilize GPU"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartModel: ['model.encoder.version', 'model.decoder.version']\n",
            "- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartForSequenceClassification: ['model.encoder.version', 'model.decoder.version']\n",
            "- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzdkdPoZEZWv",
        "outputId": "138d7c62-2d9a-4e1f-90dc-9c5593b5edd0"
      },
      "source": [
        "%%time\r\n",
        "query = \"what is the intention of Google?\"\r\n",
        "result = classifier(query, keywords_list, multi_class=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 117 ms, sys: 51.6 ms, total: 169 ms\n",
            "Wall time: 634 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9K4WqtfFhNQ",
        "outputId": "4989c52e-6a9d-4f6c-9ab9-46a9d6a2f5df"
      },
      "source": [
        "results_dict = ({score:label for label, score in zip(result['labels'], result['scores'])})\r\n",
        "dict(sorted(results_dict.items(), key=lambda item: item[1]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.0013416995061561465: 'ceo anthony goldbloom',\n",
              " 0.0015500524314120412: 'anthony goldbloom declined',\n",
              " 0.0018288666615262628: 'anthony goldbloom',\n",
              " 0.002348936628550291: 'goldbloom',\n",
              " 0.003008637111634016: 'francisco this week',\n",
              " 0.0035422123037278652: 'ceo anthony',\n",
              " 0.00473477877676487: 'kaggle',\n",
              " 0.005838700570166111: 'acquiring kaggle',\n",
              " 0.005853407084941864: 'kaggle co-founder ceo',\n",
              " 0.008472663350403309: 'san francisco',\n",
              " 0.012140297330915928: 'conference in san',\n",
              " 0.0408928208053112: 'machine learning competitions',\n",
              " 0.1127646192908287: 'machine learning',\n",
              " 0.14107631146907806: 'data',\n",
              " 0.16517511010169983: 'co-founder ceo anthony',\n",
              " 0.36291754245758057: 'google cloud',\n",
              " 0.38278794288635254: 'google cloud platform',\n",
              " 0.42713454365730286: 'service',\n",
              " 0.6460312008857727: 'platform',\n",
              " 0.9148185849189758: 'google'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsoU5HATI6hw"
      },
      "source": [
        "Inference Time on CPU:\r\n",
        "```\r\n",
        "CPU times: user 3.49 s, sys: 48.4 ms, total: 3.54 s\r\n",
        "Wall time: 3.55 s\r\n",
        "```\r\n",
        "Inference Time on GPU:\r\n",
        "```\r\n",
        "CPU times: user 117 ms, sys: 51.6 ms, total: 169 ms\r\n",
        "Wall time: 634 ms\r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNWKfO2WHnd2"
      },
      "source": [
        "### References:\r\n",
        "* https://joeddav.github.io/blog/2020/05/29/ZSL.html\r\n",
        "* https://colab.research.google.com/drive/1jocViLorbwWIkTXKwxCOV9HLTaDDgCaw?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn_sjdiSF7lL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}